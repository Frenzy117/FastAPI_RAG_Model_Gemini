{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Aq8lVqc2x-ZY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Aq8lVqc2x-ZY",
    "outputId": "91910d11-6777-4e73-bde1-a578489b4177"
   },
   "outputs": [],
   "source": [
    "%pip install langchain_community langchain_text_splitters langchain_google_genai langchain_classic faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c19a765-90ee-4b64-a99f-abc5df5710da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c19a765-90ee-4b64-a99f-abc5df5710da",
    "outputId": "8a163f4d-ee6b-47e5-f27a-2a3cc4992437"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "from langchain_classic.llms import VertexAI\n",
    "from langchain_classic.chains import ConversationalRetrievalChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import getpass\n",
    "import os\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea6e85a-1b74-425f-9dc7-c0c65cfa6259",
   "metadata": {
    "id": "2ea6e85a-1b74-425f-9dc7-c0c65cfa6259"
   },
   "outputs": [],
   "source": [
    "# Load Document (here from the web: FastAPI Official Website)\n",
    "url = \"https://fastapi.tiangolo.com/\"\n",
    "loader = WebBaseLoader(url)\n",
    "raw_documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9618a1-e4aa-447a-9589-d3644a96ca87",
   "metadata": {
    "id": "6e9618a1-e4aa-447a-9589-d3644a96ca87"
   },
   "outputs": [],
   "source": [
    "# Chunk the document text\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8bd1f1-f82e-412f-98a9-e4e35a5635c8",
   "metadata": {
    "id": "4c8bd1f1-f82e-412f-98a9-e4e35a5635c8"
   },
   "outputs": [],
   "source": [
    "# Get the API Key and Generate Text Vector Embeddings\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "    \n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1782ca-1f40-4415-995c-b991ce035718",
   "metadata": {
    "id": "8a1782ca-1f40-4415-995c-b991ce035718"
   },
   "outputs": [],
   "source": [
    "# Create a vector store and enable memory\n",
    "vector_store = FAISS.from_documents(documents,embeddings)\n",
    "memory = ConversationBufferMemory(memory_key = \"chat_history\", return_messages = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560f2cae-8de9-4ff8-ac0f-0fa3ce0c6a42",
   "metadata": {
    "id": "560f2cae-8de9-4ff8-ac0f-0fa3ce0c6a42"
   },
   "outputs": [],
   "source": [
    "# Call/instantiate the LLM and the chat\n",
    "qa = ConversationalRetrievalChain.from_llm(ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    api_key = os.environ[\"GOOGLE_API_KEY\"],\n",
    "    project= os.environ[\"GOOGLE_PROJECT_ID\"],\n",
    "    vertexai = False,\n",
    "    temperature= 0),\n",
    "    vector_store.as_retriever(),\n",
    "    memory = memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d7f6ff-cab2-46fa-a0b4-7b59bb256fcf",
   "metadata": {
    "id": "67d7f6ff-cab2-46fa-a0b4-7b59bb256fcf"
   },
   "outputs": [],
   "source": [
    "# Ask your contextual question\n",
    "query = \"How to set up FastAPI?\"\n",
    "result = qa.invoke({\"question\": query})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856e564d-21e4-4abc-b4fe-a06cfb441836",
   "metadata": {
    "id": "856e564d-21e4-4abc-b4fe-a06cfb441836",
    "outputId": "d36cd5f8-9fa7-4b44-b12a-d88163f4da26",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Eureka! (No these comments are not AI but written by me and me alone).\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51611d09-4717-4b27-971c-dfae865a87ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"I am getting an erro rwhen trying to run fastapi dev main.py. Any ideas?\"\n",
    "result2 = qa.invoke({\"question\": query2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a98eedf-72f0-4550-ae9a-4d59629e732f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(Markdown(result2[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6522b92-72ab-4136-823b-c32e57fce0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = \"How do you know about these common reasons\"\n",
    "result3 = qa.invoke({\"question\": query3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8f0c03-f46c-4b29-991b-3ee6eeb9e579",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(result3[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a2aa0f-f143-44b3-80f7-9467c5f129c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query4 = \"Describe how FastAPI works like you are explaining it to a chef\"\n",
    "result4 = qa.invoke({\"question\": query4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba756889-7381-4b64-b238-d0c36ef1bba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(Markdown(result4[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1506555a-9b19-4681-84f9-433a0327c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "query5 = \"How can I deploy my app?\"\n",
    "result5 = qa.invoke({\"question\": query5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fccf55e-a62a-4282-8d8f-e7930f9b2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(result5[\"answer\"]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
